"""
Semantic YAML Generator

This module implements Layer 3 of the AI-Native Semantic Layer Auto-Generation Platform:
- Auto-generates semantic layer YAML from AI inference results
- Creates dbt-style model definitions
- Generates comprehensive metric and dimension definitions
- Maintains version control and human-in-the-loop review capabilities
- Outputs production-ready semantic_models/metrics.yml

Technologies: YAML generation with proper formatting and validation
"""

import yaml
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
import os

from src.ai_semantic_inferrer import (
    SemanticInferenceResult,
    InferredMetric,
    InferredDimension,
    InferredEntity,
)

logger = logging.getLogger(__name__)


@dataclass
class GenerationConfig:
    """Configuration for semantic YAML generation"""

    output_path: str = "semantic_models/metrics_generated.yml"
    include_confidence_comments: bool = True
    include_ai_metadata: bool = True
    minimum_confidence: float = 0.6
    backup_existing: bool = True


class SemanticYAMLGenerator:
    """
    Auto-generates semantic layer YAML from AI inference results

    Phase 2 Implementation - Layer 3: Code Generation & Governance Engine
    """

    def __init__(self, config: Optional[GenerationConfig] = None):
        """
        Initialize YAML generator

        Args:
            config: Generation configuration options
        """
        self.config = config or GenerationConfig()

    def generate_semantic_yaml(
        self,
        inference_result: SemanticInferenceResult,
        connection_config: Dict[str, Any],
        model_name: str = "AI Generated Semantic Model",
    ) -> str:
        """
        Generate complete semantic layer YAML from AI inference results

        Args:
            inference_result: Results from AI semantic inference
            connection_config: Database connection configuration
            model_name: Name for the semantic model

        Returns:
            Generated YAML content as string
        """
        logger.info("üèóÔ∏è Generating semantic layer YAML...")

        # Build semantic model structure
        semantic_model = {
            "semantic_model": {
                "name": model_name.lower().replace(" ", "_"),
                "version": "1.0",
                "description": f'{model_name} - Auto-generated by AI on {datetime.now().strftime("%Y-%m-%d")}',
                "connection": connection_config,
                "tables": self._generate_tables_section(inference_result),
                "dimensions": self._generate_dimensions_section(inference_result),
                "metrics": self._generate_metrics_section(inference_result),
            }
        }

        # Add AI metadata if configured
        if self.config.include_ai_metadata:
            semantic_model["_ai_metadata"] = self._generate_ai_metadata(inference_result)

        # Convert to YAML with proper formatting
        yaml_content = self._format_yaml(semantic_model)

        logger.info(
            f"‚úÖ Generated semantic YAML with {len(inference_result.metrics)} metrics and {len(inference_result.dimensions)} dimensions"
        )

        return yaml_content

    def save_generated_yaml(self, yaml_content: str) -> str:
        """
        Save generated YAML to file system with backup

        Args:
            yaml_content: YAML content to save

        Returns:
            Path to saved file
        """
        output_path = Path(self.config.output_path)

        # Create directory if it doesn't exist
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Backup existing file if it exists
        if output_path.exists() and self.config.backup_existing:
            backup_path = output_path.with_suffix(
                f'.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.yml'
            )
            output_path.rename(backup_path)
            logger.info(f"üì¶ Backed up existing file to {backup_path}")

        # Save new YAML
        with open(output_path, "w") as f:
            f.write(yaml_content)

        logger.info(f"üíæ Saved generated semantic YAML to {output_path}")
        return str(output_path)

    def generate_and_save(
        self,
        inference_result: SemanticInferenceResult,
        connection_config: Dict[str, Any],
        model_name: str = "AI Generated Semantic Model",
    ) -> str:
        """
        Generate and save semantic YAML in one step

        Args:
            inference_result: Results from AI semantic inference
            connection_config: Database connection configuration
            model_name: Name for the semantic model

        Returns:
            Path to saved file
        """
        yaml_content = self.generate_semantic_yaml(inference_result, connection_config, model_name)
        return self.save_generated_yaml(yaml_content)

    def _generate_tables_section(
        self, inference_result: SemanticInferenceResult
    ) -> List[Dict[str, Any]]:
        """Generate tables section of semantic YAML"""
        tables = []

        # Group entities by table
        for entity in inference_result.entities:
            table_def = {"name": entity.table, "description": entity.description}

            # Add confidence comment if configured
            if self.config.include_confidence_comments:
                table_def["_confidence"] = f"{entity.confidence:.2f}"

            tables.append(table_def)

        return tables

    def _generate_dimensions_section(
        self, inference_result: SemanticInferenceResult
    ) -> List[Dict[str, Any]]:
        """Generate dimensions section of semantic YAML"""
        dimensions = []

        # Filter dimensions by confidence threshold
        filtered_dimensions = [
            d for d in inference_result.dimensions if d.confidence >= self.config.minimum_confidence
        ]

        for dimension in filtered_dimensions:
            dim_def = {
                "name": dimension.name,
                "display_name": dimension.display_name,
                "description": dimension.description,
                "column": dimension.column,
                "table": dimension.table,
                "type": self._map_dimension_type(dimension),
            }

            # Add sample values for categorical dimensions
            if dimension.sample_values and dimension.data_type.lower() in ["string", "varchar"]:
                dim_def["sample_values"] = dimension.sample_values

            # Add confidence comment if configured
            if self.config.include_confidence_comments:
                dim_def["_confidence"] = f"{dimension.confidence:.2f}"

            dimensions.append(dim_def)

        return dimensions

    def _generate_metrics_section(
        self, inference_result: SemanticInferenceResult
    ) -> List[Dict[str, Any]]:
        """Generate metrics section of semantic YAML"""
        metrics = []

        # Filter metrics by confidence threshold
        filtered_metrics = [
            m for m in inference_result.metrics if m.confidence >= self.config.minimum_confidence
        ]

        for metric in filtered_metrics:
            metric_def = {
                "name": metric.name,
                "display_name": metric.display_name,
                "description": metric.description,
                "type": metric.type,
                "calculation": self._format_metric_calculation(metric),
            }

            # Add confidence comment if configured
            if self.config.include_confidence_comments:
                metric_def["_confidence"] = f"{metric.confidence:.2f}"
                metric_def["_business_context"] = metric.business_context

            metrics.append(metric_def)

        return metrics

    def _map_dimension_type(self, dimension: InferredDimension) -> str:
        """Map inferred dimension to semantic layer dimension type"""
        if any(x in dimension.data_type.lower() for x in ["date", "timestamp"]):
            return "time"
        elif dimension.data_type.lower() in ["string", "varchar"]:
            return "categorical"
        else:
            return "categorical"  # Default for numeric dimensions

    def _format_metric_calculation(self, metric: InferredMetric) -> Dict[str, Any]:
        """Format metric calculation for YAML output"""
        if metric.type == "simple":
            return {
                "table": metric.calculation["table"],
                "aggregation": metric.calculation["aggregation"],
                "column": metric.calculation["column"],
                "filters": metric.calculation.get("filters", []),
            }
        elif metric.type == "derived":
            return {"formula": metric.calculation["formula"]}
        else:
            return metric.calculation

    def _generate_ai_metadata(self, inference_result: SemanticInferenceResult) -> Dict[str, Any]:
        """Generate AI metadata section for transparency"""
        return {
            "generated_at": inference_result.inference_timestamp,
            "generator": "AI Semantic Inference Engine v1.0",
            "confidence_summary": inference_result.confidence_summary,
            "business_domains": inference_result.business_domains,
            "total_entities": len(inference_result.entities),
            "total_metrics": len(inference_result.metrics),
            "total_dimensions": len(inference_result.dimensions),
            "notes": [
                "This file was auto-generated using AI analysis of warehouse metadata.",
                "Review and validate all metrics and dimensions before production use.",
                "Confidence scores indicate AI certainty - higher is better.",
                f"Minimum confidence threshold applied: {self.config.minimum_confidence}",
            ],
        }

    def _format_yaml(self, data: Dict[str, Any]) -> str:
        """Format YAML with proper indentation and comments"""
        # Custom YAML formatting for better readability
        yaml_str = yaml.dump(
            data, default_flow_style=False, sort_keys=False, indent=2, allow_unicode=True
        )

        # Add header comment
        header = f"""# Auto-Generated Semantic Layer Configuration
# Generated on: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} UTC
# Generator: AI Semantic Inference Engine v1.0
#
# This file contains auto-generated metric and dimension definitions
# based on AI analysis of your warehouse metadata.
#
# IMPORTANT: Review all definitions before production use!
#
# Legend:
#   _confidence: AI confidence score (0.0 - 1.0, higher is better)
#   _business_context: AI-inferred business context

"""

        return header + yaml_str

    def validate_generated_yaml(self, yaml_content: str) -> Dict[str, Any]:
        """
        Validate generated YAML for correctness and completeness

        Args:
            yaml_content: YAML content to validate

        Returns:
            Validation results with any issues found
        """
        validation_results = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "metrics_count": 0,
            "dimensions_count": 0,
        }

        try:
            # Parse YAML to check syntax
            parsed = yaml.safe_load(yaml_content)

            # Check required sections
            if "semantic_model" not in parsed:
                validation_results["errors"].append("Missing 'semantic_model' root section")
                validation_results["is_valid"] = False

            semantic_model = parsed.get("semantic_model", {})

            # Validate required fields
            required_fields = ["name", "connection", "metrics"]
            for field in required_fields:
                if field not in semantic_model:
                    validation_results["errors"].append(f"Missing required field: '{field}'")
                    validation_results["is_valid"] = False

            # Count metrics and dimensions
            metrics = semantic_model.get("metrics", [])
            dimensions = semantic_model.get("dimensions", [])

            validation_results["metrics_count"] = len(metrics)
            validation_results["dimensions_count"] = len(dimensions)

            # Check for empty sections
            if not metrics:
                validation_results["warnings"].append("No metrics defined")
            if not dimensions:
                validation_results["warnings"].append("No dimensions defined")

            # Validate metric structures
            for i, metric in enumerate(metrics):
                if "name" not in metric:
                    validation_results["errors"].append(f"Metric {i} missing 'name' field")
                    validation_results["is_valid"] = False
                if "calculation" not in metric:
                    validation_results["errors"].append(f"Metric {i} missing 'calculation' field")
                    validation_results["is_valid"] = False

        except yaml.YAMLError as e:
            validation_results["errors"].append(f"YAML syntax error: {e}")
            validation_results["is_valid"] = False

        except Exception as e:
            validation_results["errors"].append(f"Validation error: {e}")
            validation_results["is_valid"] = False

        return validation_results


# Example usage and testing
if __name__ == "__main__":
    import ibis
    from src.metadata_inspector import MetadataInspector
    from src.ai_semantic_inferrer import AISemanticInferrer

    # Test full pipeline: Introspection ‚Üí AI Inference ‚Üí YAML Generation
    print("üöÄ Testing Full Auto-Generation Pipeline")
    print("=" * 50)

    # Step 1: Introspect warehouse
    connection = ibis.duckdb.connect("/tmp/sample_metadata.duckdb")
    inspector = MetadataInspector(connection)
    metadata = inspector.introspect_warehouse()
    print(f"‚úÖ Introspected {len(metadata)} tables")

    # Step 2: Run AI inference
    ai_inferrer = AISemanticInferrer(use_local_inference=True)
    inference_result = ai_inferrer.infer_semantic_model(metadata)
    print(
        f"‚úÖ AI inference: {len(inference_result.metrics)} metrics, {len(inference_result.dimensions)} dimensions"
    )

    # Step 3: Generate semantic YAML
    config = GenerationConfig(
        output_path="semantic_models/ai_generated_metrics.yml",
        include_confidence_comments=True,
        include_ai_metadata=True,
        minimum_confidence=0.7,
    )

    generator = SemanticYAMLGenerator(config)

    connection_config = {
        "type": "duckdb",
        "database": "/Users/mattstrautmann/Documents/github/knowDB/data/sample.duckdb",
    }

    yaml_content = generator.generate_semantic_yaml(
        inference_result, connection_config, "AI-Generated SaaS Metrics"
    )

    # Step 4: Validate YAML
    validation = generator.validate_generated_yaml(yaml_content)
    print(f"\nüìã YAML Validation:")
    print(f"  Valid: {validation['is_valid']}")
    print(f"  Metrics: {validation['metrics_count']}")
    print(f"  Dimensions: {validation['dimensions_count']}")
    if validation["errors"]:
        print(f"  Errors: {validation['errors']}")
    if validation["warnings"]:
        print(f"  Warnings: {validation['warnings']}")

    # Step 5: Save to file
    saved_path = generator.save_generated_yaml(yaml_content)
    print(f"\nüíæ Saved to: {saved_path}")

    # Show sample of generated YAML
    print(f"\nüìÑ Generated YAML Preview:")
    print("-" * 30)
    lines = yaml_content.split("\n")
    for line in lines[:25]:  # Show first 25 lines
        print(line)
    print("...")
    print("-" * 30)

    print(f"\nüéâ Auto-generation pipeline complete!")
    print(f"üìÅ Check {saved_path} for full generated semantic model")
